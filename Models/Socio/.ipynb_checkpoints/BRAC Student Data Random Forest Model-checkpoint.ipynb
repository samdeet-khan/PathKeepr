{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e468f95-9f5c-40ae-8826-cef9801ef5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de35606-313a-426c-9290-17101a8d45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('filtered_student_data.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8b20df-6a6b-4062-a2ff-f1f48e3ab7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['dropout', 'birth_certificate_id'], axis=1)\n",
    "y = df['dropout']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd74de5c-ad29-41fc-bea4-4a70d9f9da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samdeet.khan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8831941505201931\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94    139169\n",
      "           1       0.60      0.04      0.07     18657\n",
      "\n",
      "    accuracy                           0.88    157826\n",
      "   macro avg       0.74      0.52      0.50    157826\n",
      "weighted avg       0.85      0.88      0.83    157826\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138728    441]\n",
      " [ 17994    663]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['dropout', 'birth_certificate_id'], axis=1)\n",
    "y = df['dropout']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Define the preprocessing for numerical columns (scaling and imputing missing values)\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define the preprocessing for categorical columns (imputing missing values and applying a one-hot encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Define the column transformer to apply the different preprocessors to the respective columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create the Logistic Regression model with Elastic Net regularization\n",
    "model = LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1.0, random_state=0, solver='saga', max_iter=1000)\n",
    "\n",
    "# Create the full pipeline including the preprocessor and the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', model)])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['dropout', 'birth_certificate_id'], axis=1)  # Remove 'birth_certificate_id' as it's typically not useful for modeling\n",
    "y = df['dropout']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9884e7df-93e2-4451-a09d-17352ac2e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with class weights\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0, class_weight='balanced', max_depth=100)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = ImbPipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('smote', SMOTE(random_state=0)),\n",
    "                              ('model', model)])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd69ae2f-c1d3-44a8-80c6-367da8a2dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7025458416230532\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80    139169\n",
      "           1       0.26      0.80      0.39     18657\n",
      "\n",
      "    accuracy                           0.70    157826\n",
      "   macro avg       0.61      0.75      0.60    157826\n",
      "weighted avg       0.88      0.70      0.75    157826\n",
      "\n",
      "Confusion Matrix:\n",
      " [[95924 43245]\n",
      " [ 3701 14956]]\n",
      "ROC AUC Score: 0.7454460551148095\n",
      "Precision-Recall Curve:\n",
      " [(np.float64(0.11821246182504784), np.float64(1.0), np.int64(0)), (np.float64(0.25697152969880244), np.float64(0.8016294152328884), np.int64(1))]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "print(\"Precision-Recall Curve:\\n\", list(zip(precision, recall, thresholds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fba9666-f84a-4b48-b8a5-06f78a0157de",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1911 is out of bounds for axis 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), importances[indices], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)), \u001b[43mfeature_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m, rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(importances)])\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1911 is out of bounds for axis 0 with size 15"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline.named_steps['model']\n",
    "feature_names = np.array(X.columns)  # Adjust if preprocessing changes the features\n",
    "\n",
    "# Get the feature importances from the random forest model\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order and get the indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(len(importances)), importances[indices], color='b', align='center')\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, len(importances)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd43b404-119c-495a-a534-217d4b9a0111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birth_certificate_id', 'sex', 'father_educational_attainment', 'mother_educational_attainment', 'grade_id', 'relation_with_guardian', 'pwd_type', 'pwd_degree', 'marital_status']\n",
      "['is_orphan', 'is_never_been_to_school', 'is_ethnic', 'parents_income', 'previous_dropout', 'received_any_treatment', 'newly_admitted']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_cols)\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b200fff-5c3c-440d-bdd8-007b5f17ddef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:971\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    970\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 971\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D input, got input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:631\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    626\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    627\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_container\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    628\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43msparse_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# TODO: Remove when the minimum version of SciPy supported is 1.12\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# With SciPy sparse arrays, conversion from DIA format to COO, CSR, or BSR\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# triggers the use of `np.int64` indices even if the data is such that it could\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# algorithms support large indices, the following code downcasts to `np.int32`\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# indices when it's safe to do so.\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_format:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;66;03m# accept_sparse is specified to a specific format and a conversion occurred\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('filtered_student_data.csv', low_memory=False)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_cols = ['sex', 'father_educational_attainment', 'mother_educational_attainment', 'grade_id', 'relation_with_guardian', 'pwd_type', 'pwd_degree', 'marital_status']\n",
    "numerical_cols = ['is_orphan', 'is_never_been_to_school', 'is_ethnic', 'parents_income', 'previous_dropout', 'received_any_treatment', 'newly_admitted']\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create a pipeline with Elastic Net regularization\n",
    "model = LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1.0, random_state=0, solver='saga', max_iter=1000)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', model)])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['dropout', 'birth_certificate_id'], axis=1)  # Remove 'birth_certificate_id' as it's typically not useful for modeling\n",
    "y = df['dropout']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1573d-2017-4cff-942e-0327f7e8e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Extract and print the coefficients for the logistic regression to understand the relationship between variables and the outcome\n",
    "feature_names = np.concatenate([numerical_cols, pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)])\n",
    "coefficients = pipeline.named_steps['classifier'].coef_[0]\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
